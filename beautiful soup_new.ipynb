{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75693c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\my pc\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: req in c:\\users\\my pc\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from req) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "##Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’\n",
    "!pip install bs4\n",
    "!pip install req\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b92ce3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page=requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "##page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81f0667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4eef41e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 ---> Main Page\n",
      "h2 ---> From today's featured article\n",
      "h2 ---> Did you know ...\n",
      "h2 ---> In the news\n",
      "h2 ---> On this day\n",
      "h2 ---> From today's featured list\n",
      "h2 ---> Today's featured picture\n",
      "h2 ---> Other areas of Wikipedia\n",
      "h2 ---> Wikipedia's sister projects\n",
      "h2 ---> Wikipedia languages\n",
      "h2 ---> Navigation menu\n",
      "h3 ---> Personal tools\n",
      "h3 ---> Namespaces\n",
      "h3 ---> Variants\n",
      "h3 ---> Views\n",
      "h3 ---> More\n",
      "h3 ---> Search\n",
      "h3 ---> Navigation\n",
      "h3 ---> Contribute\n",
      "h3 ---> Tools\n",
      "h3 ---> Print/export\n",
      "h3 ---> In other projects\n",
      "h3 ---> Languages\n"
     ]
    }
   ],
   "source": [
    "##extract header tags\n",
    "\n",
    "heading_tags = ['h1','h2','h3','h4']\n",
    "for i in soup.find_all(heading_tags):\n",
    "    print(i.name + ' ---> ' + i.text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6f8bcaf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release\n",
    "imdb_page=requests.get(\"https://www.imdb.com/chart/top/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba7043be",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_soup=BeautifulSoup(imdb_page.content)\n",
    "top_movie=imdb_soup.find_all('td',class_=\"titleColumn\")\n",
    "rating1=imdb_soup.find_all('td',class_=\"ratingColumn imdbRating\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2c30b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1.      The Shawshank Redemption(1994)--->9.2\n",
      "      2.      The Godfather(1972)--->9.1\n",
      "      3.      The Godfather: Part II(1974)--->9.0\n",
      "      4.      The Dark Knight(2008)--->9.0\n",
      "      5.      12 Angry Men(1957)--->8.9\n",
      "      6.      Schindler's List(1993)--->8.9\n",
      "      7.      The Lord of the Rings: The Return of the King(2003)--->8.9\n",
      "      8.      Pulp Fiction(1994)--->8.8\n",
      "      9.      Il buono, il brutto, il cattivo(1966)--->8.8\n",
      "      10.      The Lord of the Rings: The Fellowship of the Ring(2001)--->8.8\n",
      "      11.      Fight Club(1999)--->8.8\n",
      "      12.      Forrest Gump(1994)--->8.7\n",
      "      13.      Inception(2010)--->8.7\n",
      "      14.      The Lord of the Rings: The Two Towers(2002)--->8.7\n",
      "      15.      Star Wars: Episode V - The Empire Strikes Back(1980)--->8.7\n",
      "      16.      The Matrix(1999)--->8.6\n",
      "      17.      Goodfellas(1990)--->8.6\n",
      "      18.      One Flew Over the Cuckoo's Nest(1975)--->8.6\n",
      "      19.      Shichinin no samurai(1954)--->8.6\n",
      "      20.      Se7en(1995)--->8.6\n",
      "      21.      Cidade de Deus(2002)--->8.6\n",
      "      22.      The Silence of the Lambs(1991)--->8.6\n",
      "      23.      La vita è bella(1997)--->8.6\n",
      "      24.      It's a Wonderful Life(1946)--->8.6\n",
      "      25.      Star Wars(1977)--->8.6\n",
      "      26.      Saving Private Ryan(1998)--->8.5\n",
      "      27.      Sen to Chihiro no kamikakushi(2001)--->8.5\n",
      "      28.      Interstellar(2014)--->8.5\n",
      "      29.      The Green Mile(1999)--->8.5\n",
      "      30.      Gisaengchung(2019)--->8.5\n",
      "      31.      Léon(1994)--->8.5\n",
      "      32.      Seppuku(1962)--->8.5\n",
      "      33.      The Usual Suspects(1995)--->8.5\n",
      "      34.      The Pianist(2002)--->8.5\n",
      "      35.      Back to the Future(1985)--->8.5\n",
      "      36.      Terminator 2: Judgment Day(1991)--->8.5\n",
      "      37.      Modern Times(1936)--->8.5\n",
      "      38.      Psycho(1960)--->8.5\n",
      "      39.      The Lion King(1994)--->8.5\n",
      "      40.      American History X(1998)--->8.5\n",
      "      41.      City Lights(1931)--->8.5\n",
      "      42.      Hotaru no haka(1988)--->8.5\n",
      "      43.      Gladiator(2000)--->8.5\n",
      "      44.      Whiplash(2014)--->8.5\n",
      "      45.      The Departed(2006)--->8.5\n",
      "      46.      The Intouchables(2011)--->8.5\n",
      "      47.      The Prestige(2006)--->8.5\n",
      "      48.      Casablanca(1942)--->8.4\n",
      "      49.      Once Upon a Time in the West(1968)--->8.4\n",
      "      50.      Rear Window(1954)--->8.4\n",
      "      51.      Nuovo Cinema Paradiso(1988)--->8.4\n",
      "      52.      Alien(1979)--->8.4\n",
      "      53.      Apocalypse Now(1979)--->8.4\n",
      "      54.      Memento(2000)--->8.4\n",
      "      55.      Raiders of the Lost Ark(1981)--->8.4\n",
      "      56.      The Great Dictator(1940)--->8.4\n",
      "      57.      The Lives of Others(2006)--->8.4\n",
      "      58.      Django Unchained(2012)--->8.4\n",
      "      59.      Paths of Glory(1957)--->8.4\n",
      "      60.      Sunset Blvd.(1950)--->8.4\n",
      "      61.      WALL·E(2008)--->8.4\n",
      "      62.      The Shining(1980)--->8.4\n",
      "      63.      Avengers: Infinity War(2018)--->8.4\n",
      "      64.      Witness for the Prosecution(1957)--->8.4\n",
      "      65.      Joker(2019)--->8.4\n",
      "      66.      Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb(1964)--->8.4\n",
      "      67.      Spider-Man: Into the Spider-Verse(2018)--->8.4\n",
      "      68.      Oldeuboi(2003)--->8.3\n",
      "      69.      Mononoke-hime(1997)--->8.3\n",
      "      70.      Hamilton(2020)--->8.3\n",
      "      71.      Kimi no na wa.(2016)--->8.3\n",
      "      72.      Once Upon a Time in America(1984)--->8.3\n",
      "      73.      The Dark Knight Rises(2012)--->8.3\n",
      "      74.      Aliens(1986)--->8.3\n",
      "      75.      Coco(2017)--->8.3\n",
      "      76.      Das Boot(1981)--->8.3\n",
      "      77.      Capharnaüm(2018)--->8.3\n",
      "      78.      Avengers: Endgame(2019)--->8.3\n",
      "      79.      Tengoku to jigoku(1963)--->8.3\n",
      "      80.      American Beauty(1999)--->8.3\n",
      "      81.      Toy Story(1995)--->8.3\n",
      "      82.      3 Idiots(2009)--->8.3\n",
      "      83.      Braveheart(1995)--->8.3\n",
      "      84.      Amadeus(1984)--->8.3\n",
      "      85.      Pather Panchali(1955)--->8.3\n",
      "      86.      Inglourious Basterds(2009)--->8.3\n",
      "      87.      Good Will Hunting(1997)--->8.3\n",
      "      88.      Star Wars: Episode VI - Return of the Jedi(1983)--->8.3\n",
      "      89.      2001: A Space Odyssey(1968)--->8.3\n",
      "      90.      Reservoir Dogs(1992)--->8.3\n",
      "      91.      Taare Zameen Par(2007)--->8.3\n",
      "      92.      M - Eine Stadt sucht einen Mörder(1931)--->8.3\n",
      "      93.      Vertigo(1958)--->8.3\n",
      "      94.      Citizen Kane(1941)--->8.3\n",
      "      95.      Jagten(2012)--->8.3\n",
      "      96.      Requiem for a Dream(2000)--->8.3\n",
      "      97.      Idi i smotri(1985)--->8.3\n",
      "      98.      Singin' in the Rain(1952)--->8.3\n",
      "      99.      North by Northwest(1959)--->8.3\n",
      "      100.      Eternal Sunshine of the Spotless Mind(2004)--->8.3\n"
     ]
    }
   ],
   "source": [
    "movie=[]\n",
    "movie_rat=[]\n",
    "for i in top_movie:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movie.append(i.text.replace(\"\\n\",\"\")) \n",
    "for i in rating1:\n",
    "    for j in i.find_all(\"strong\"):\n",
    "        movie_rat.append(i.text.replace(\"\\n\",\"\"))\n",
    "for k in range(0,100):\n",
    "    print(movie[k]+\"--->\"+movie_rat[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36530ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release\n",
    "imdb_indian_page=requests.get(\"https://www.imdb.com/list/ls056092300/\")\n",
    "imdb_indian_page\n",
    "##imdb_indian_page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "915ae708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Ship of Theseus(2012)--->8.1\n",
      "2.Iruvar(1997)--->8.5\n",
      "3.Kaagaz Ke Phool(1959)--->8\n",
      "4.Lagaan: Once Upon a Time in India(2001)--->8.1\n",
      "5.Pather Panchali(1955)--->8.5\n",
      "6.Charulata(1964)--->8.2\n",
      "7.Rang De Basanti(2006)--->8.1\n",
      "8.Dev.D(2009)--->8\n",
      "9.3 Idiots(2009)--->8.4\n",
      "10.Awaara(1951)--->7.9\n",
      "11.Nayakan(1987)--->8.7\n",
      "12.Aparajito(1956)--->8.4\n",
      "13.Pushpaka Vimana(1987)--->8.6\n",
      "14.Pyaasa(1957)--->8.5\n",
      "15.Ghatashraddha(1977)--->7.2\n",
      "16.Sholay(1975)--->8.2\n",
      "17.Aradhana(1969)--->7.6\n",
      "18.Do Ankhen Barah Haath(1957)--->8.4\n",
      "19.Bombay(1995)--->8.1\n",
      "20.Neecha Nagar(1946)--->6.8\n",
      "21.Do Bigha Zamin(1953)--->8.4\n",
      "22.Garm Hava(1974)--->8.1\n",
      "23.Piravi(1989)--->7.7\n",
      "24.Mughal-E-Azam(1960)--->8.2\n",
      "25.Amma Ariyan(1986)--->7.1\n",
      "26.Madhumati(1958)--->8\n",
      "27.Goopy Gyne Bagha Byne(1969)--->8.8\n",
      "28.Gangs of Wasseypur(2012)--->8.2\n",
      "29.Guide(1965)--->8.4\n",
      "30.Satya(1998)--->8.2\n",
      "31.Roja(1992)--->8.2\n",
      "32.Mr. India(1987)--->7.8\n",
      "33.The Cloud-Capped Star(1960)--->8\n",
      "34.Harishchandrachi Factory(2009)--->8.4\n",
      "35.Masoom(1983)--->8.4\n",
      "36.Agneepath(1990)--->7.7\n",
      "37.Tabarana Kathe(1986)--->8\n",
      "38.Zakhm(1998)--->7.9\n",
      "39.Dil Chahta Hai(2001)--->8.1\n",
      "40.Bhaag Milkha Bhaag(2013)--->8.2\n",
      "41.Chupke Chupke(1975)--->8.3\n",
      "42.Dilwale Dulhania Le Jayenge(1995)--->8.1\n",
      "43.Taare Zameen Par(2007)--->8.4\n",
      "44.Ardh Satya(1983)--->8.2\n",
      "45.Bhumika(1977)--->7.4\n",
      "46.Enthiran(2010)--->7.1\n",
      "47.Sadma(1983)--->8.4\n",
      "48.Shwaas(2004)--->8.3\n",
      "49.Lamhe(1991)--->7.4\n",
      "50.Haqeeqat(1964)--->7.8\n",
      "51.Shree 420(1955)--->8\n",
      "52.Kannathil Muthamittal(2002)--->8.4\n",
      "53.Hum Aapke Hain Koun...!(1994)--->7.5\n",
      "54.Ustad Hotel(2012)--->8.2\n",
      "55.Bandit Queen(1994)--->7.6\n",
      "56.Lakshya(2004)--->7.9\n",
      "57.Black Friday(2004)--->8.5\n",
      "58.Manthan(1976)--->7.7\n",
      "59.Apoorva Raagangal(1975)--->7.5\n",
      "60.English Vinglish(2012)--->7.8\n",
      "61.Jewel Thief(1967)--->8\n",
      "62.Pakeezah(1972)--->7.3\n",
      "63.Maqbool(2003)--->8.1\n",
      "64.Jis Desh Men Ganga Behti Hai(1960)--->7.4\n",
      "65.Sahib Bibi Aur Ghulam(1962)--->8.3\n",
      "66.Shatranj Ke Khilari(1977)--->7.7\n",
      "67.Narthanasala(1963)--->7.6\n",
      "68.Chandni Bar(2001)--->7.6\n",
      "69.Vaaranam Aayiram(2008)--->8.2\n",
      "70.Mr. and Mrs. Iyer(2002)--->7.9\n",
      "71.Chandni(1989)--->6.8\n",
      "72.English, August(1994)--->6.8\n",
      "73.Celluloid(2013)--->7.7\n",
      "74.Sagara Sangamam(1983)--->8.8\n",
      "75.Munna Bhai M.B.B.S.(2003)--->8.1\n",
      "76.Saaransh(1984)--->8.2\n",
      "77.Guddi(1971)--->7.2\n",
      "78.Vanaja(2006)--->7.1\n",
      "79.Vazhakku Enn 18/9(2012)--->8.3\n",
      "80.Gangaajal(2003)--->7.8\n",
      "81.Angoor(1982)--->8.3\n",
      "82.Guru(2007)--->7.7\n",
      "83.Andaz Apna Apna(1994)--->8.1\n",
      "84.Sangam(I) (1964)--->7.5\n",
      "85.Oka Oori Katha(1978)--->7.5\n",
      "86.Bhuvan Shome(1969)--->7.5\n",
      "87.Border(I) (1997)--->7.9\n",
      "88.Parineeta(2005)--->7.2\n",
      "89.Devdas(1955)--->7.9\n",
      "90.Abohomaan(2009)--->7.4\n",
      "91.Kuch Kuch Hota Hai(1998)--->7.6\n",
      "92.Pithamagan(2003)--->8.4\n",
      "93.Veyyil(2006)--->7.7\n",
      "94.Chemmeen(1965)--->7.7\n",
      "95.Jaane Bhi Do Yaaro(1983)--->8.4\n",
      "96.Apur Sansar(1959)--->8.5\n",
      "97.Kanchivaram(2008)--->8.1\n",
      "98.Monsoon Wedding(2001)--->7.4\n",
      "99.Black(2005)--->8.2\n",
      "100.Deewaar(1975)--->8.1\n"
     ]
    }
   ],
   "source": [
    "imdb_indian_soup=BeautifulSoup(imdb_indian_page.content)\n",
    "top_movie=imdb_indian_soup.find_all('h3',class_=\"lister-item-header\")\n",
    "rating=imdb_indian_soup.find_all('div',class_=\"ipl-rating-star small\")\n",
    "i_movie=[]\n",
    "i_movie_rat=[]\n",
    "for i in top_movie:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        i_movie.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in rating:\n",
    "    for j in i.find_all(\"span\",class_=\"ipl-rating-star__rating\"):\n",
    "        i_movie_rat.append(i.text.replace(\"\\n\",\"\"))\n",
    "for k in range(0,len(i_movie)):\n",
    "    print(i_movie[k]+\"--->\"+i_movie_rat[k])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f24e5",
   "metadata": {},
   "source": [
    "Write a python program to scrap book name, author name, genre and book review of any 5 books from \n",
    "‘www.bookpage.com’ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f97cf286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "book_page=requests.get(\"https://bookpage.com/\")\n",
    "##book_page.content\n",
    "book_soup=BeautifulSoup(book_page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76ec709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First-day feelings\n",
      "Feature by Alice Cary\n",
      "Children's\n",
      " / \n",
      "Children's Picture Book\n",
      "These four picture books ensure children will approach the first day of school with confidence and kindness.\n",
      "Read More \n",
      "Battles of the heart\n",
      "Feature by Elizabeth Mazer\n",
      "Romance\n",
      " / \n",
      "Historical Romance\n",
      "Upstanding soldiers get swept away by unconventional, openhearted women in two historical romances.\n",
      "Read More \n",
      "We Are Each Other’s Harvest\n",
      "Review by Mari Carlson\n",
      "Audio\n",
      " / \n",
      "Nonfiction\n",
      " / \n",
      "African American History\n",
      "With rich descriptions of crops, recipes, family meals and more, this audiobook inspires, empowers and enlightens through spoken word.\n",
      "Read More \n",
      " ★ Dead Wednesday\n",
      "Review by Alice Cary\n",
      "Children's\n",
      " / \n",
      "Middle Grade\n",
      "On Dead Wednesday, eighth graders assume the identities of recently deceased teens, but Worm never expected that Becca’s ghost would actually materialize.\n",
      "Read More \n",
      "The Wreckage of My Presence\n",
      "Review by Anna Zeitlin\n",
      "Audio\n",
      " / \n",
      "Nonfiction\n",
      " / \n",
      "Essays\n",
      "Listening to Casey Wilson’s essay collection is like getting good gossip from one of your funniest friends.\n",
      "Read More \n"
     ]
    }
   ],
   "source": [
    "content=book_soup.find_all(\"div\",class_=\"content\")\n",
    "##author=page_soup.find_all('div',class_=\"ipl-rating-star small\")\n",
    "name=[]\n",
    "authour=[]\n",
    "genre=[]\n",
    "for i in content:\n",
    "    for j in i.find_all(\"h4\",class_=\"italic\"):\n",
    "        for k in j.find_all(\"a\"):\n",
    "            name.append(i.text.replace(\"\\n\\n\",\"\"))\n",
    "for p in range(0,5):\n",
    "    print(name[p])\n",
    "   ## for j in i.find_all(\"p\",class_=\"ipl-rating-star__rating\"):\n",
    "        \n",
    "##for a in range(0,5):\n",
    "    ##print(name[a]+\":\"+author[a]+\":\"+genre[a])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ac058",
   "metadata": {},
   "source": [
    "\t5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape: i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating. \n",
    "\tii) Top 10 ODI Batsmen in men along with the records of their team and rating. \n",
    "\tiii) Top 10 ODI bowlers along with the records of their team and rating. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1aab1cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 1   New Zealand NZ  17 2,054                              121                                ']\n",
      " 2   England ENG  32 3,793 119 \n",
      " 3   Australia AUS  26 3,077 118 \n",
      " 4   India IND  31 3,598 116 \n",
      " 5   South Africa SA  22 2,267 103 \n",
      " 6   Pakistan PAK  27 2,524 93 \n",
      " 7   Bangladesh BAN  29 2,639 91 \n",
      " 8   West Indies WI  28 2,290 82 \n",
      " 9   Sri Lanka SL  28 2,137 76 \n",
      " 10   Afghanistan AFG  17 1,054 62 \n"
     ]
    }
   ],
   "source": [
    "odi_page=requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\") \n",
    "odi_soup=BeautifulSoup(odi_page.content)\n",
    "top_team=odi_soup.find_all('tr',class_=\"table-body\")\n",
    "info_team=odi_soup.find_all('tr',class_=\"rankings-block__banner\")\n",
    "team=[]\n",
    "info=[]\n",
    "for i in info_team:\n",
    "    for m in i.find_all(\"td\",class_=\"rankings-block__banner--team-name\"):\n",
    "        for l in m.find_all(\"span\",class_=\"u-hide-phablet\"):\n",
    "            info.append(i.text.replace(\"\\n\",\" \"))\n",
    "for i in top_team:\n",
    "    for j in i.find_all(\"td\",class_=\"table-body__cell rankings-table__team\"):\n",
    "        for k in j.find_all(\"span\",class_=\"u-hide-phablet\"):\n",
    "            team.append(i.text.replace(\"\\n\",\" \"))\n",
    "print(info)\n",
    "for r in range(0,9):\n",
    "    print(team[r])\n",
    "    ##print(info[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a07633",
   "metadata": {},
   "source": [
    "Top 10 ODI Batsman in men along with the records of their team and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c63fba74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    1            Babar Azam   PAK                             873       \n",
      "                                    2        Virat KohliIND848\n",
      "                                    3        Rohit SharmaIND817\n",
      "                                    4        Ross TaylorNZ801\n",
      "                                    5        Aaron FinchAUS791\n",
      "                                    6        Jonny BairstowENG775\n",
      "                                    7        David WarnerAUS773\n",
      "                                              Shai HopeWI773\n",
      "                                    9        Francois du PlessisSA766\n",
      "                                    10        Quinton de KockSA758\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "odi_page1=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\") \n",
    "odi_soup1=BeautifulSoup(odi_page1.content)\n",
    "top_batsman=odi_soup1.find_all('tr',class_=\"table-body\")\n",
    "first=odi_soup1.find_all('a',class_=\"rankings-block__banner-link\")\n",
    "batsman=[]\n",
    "first_rank=[]\n",
    "for i in first:\n",
    "    for  j in i.find_all(\"div\",class_=\"rankings-block__top-player\"):\n",
    "        for  k in j.find_all(\"div\",class_=\"rankings-block__banner--name\"):\n",
    "            first_rank.append(i.text.replace(\"\\n\",\" \"))\n",
    "for i in top_batsman:\n",
    "    for  j in i.find_all(\"td\",class_=\"table-body__cell name\"):\n",
    "        for  k in j.find_all(\"a\"):\n",
    "            batsman.append(i.text.replace(\"\\n\",\"\"))\n",
    "print(\"        \",first_rank[0])\n",
    "for r in range(0,9):\n",
    "      print(batsman[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b796d442",
   "metadata": {},
   "source": [
    "Top 10 ODI Bowlers in men along with the records of their team and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c869a096",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import regex as re\n",
    "odi_page1=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\") \n",
    "odi_soup1=BeautifulSoup(odi_page1.content)\n",
    "top_bowler=odi_soup1.find_all(\"div\",class_=\"rankings-block__container\")\n",
    "first=odi_soup1.find_all('a',class_=\"rankings-block__banner-link\")\n",
    "bowler=[]\n",
    "info=[]\n",
    "for i in top_bowler:\n",
    "    for  j in i.find_all(\"tr\",class_=\"table-body\"):\n",
    "        for  k in j.find_all(\"td\",class_=\"table-body__cell name\"):\n",
    "            for  l in k.find_all(\"a\",href=\"/rankings/mens/player-rankings/4572\"):\n",
    "                bowler.append(i.text.strip())\n",
    "\n",
    "print(bowler[0].replace(\"\\n\",\"\\t\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c9156",
   "metadata": {},
   "source": [
    "6.Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape: i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating. 一 ii) Top 10 women’s ODI players along with the records of their team and rating. 一 iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d46c066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 1   Australia AUS  18 2,955                              164                                ']\n",
      " 2   England ENG  20 2,370 119 \n",
      " 3   South Africa SA  24 2,828 118 \n",
      " 4   India IND  23 2,535 110 \n",
      " 5   New Zealand NZ  21 1,947 93 \n",
      " 6   West Indies WI  17 1,427 84 \n",
      " 7   Pakistan PAK  20 1,496 75 \n",
      " 8   Bangladesh BAN  5 306 61 \n",
      " 9   Sri Lanka SL  11 519 47 \n",
      " 10   Ireland IRE  2 25 13 \n"
     ]
    }
   ],
   "source": [
    "odi_page=requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\") \n",
    "odi_soup=BeautifulSoup(odi_page.content)\n",
    "top_team=odi_soup.find_all('tr',class_=\"table-body\")\n",
    "info_team=odi_soup.find_all('tr',class_=\"rankings-block__banner\")\n",
    "team=[]\n",
    "info=[]\n",
    "for i in info_team:\n",
    "    for m in i.find_all(\"td\",class_=\"rankings-block__banner--team-name\"):\n",
    "        for l in m.find_all(\"span\",class_=\"u-hide-phablet\"):\n",
    "            info.append(i.text.replace(\"\\n\",\" \"))\n",
    "for i in top_team:\n",
    "    for j in i.find_all(\"td\",class_=\"table-body__cell rankings-table__team\"):\n",
    "        for k in j.find_all(\"span\",class_=\"u-hide-phablet\"):\n",
    "            team.append(i.text.replace(\"\\n\",\" \"))\n",
    "\n",
    "print(info)\n",
    "for r in range(0,len(team)):\n",
    "    print(team[r])\n",
    "##print(top_team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59898246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      1            Mithali Raj   IND                             762       \n",
      "                                      2            Lizelle Lee    SA  758 \n",
      "                                      3            Alyssa Healy    AUS  756 \n",
      "                                      4            Tammy Beaumont    ENG  754 \n",
      "                                      5            Stafanie Taylor    WI  736 \n",
      "                                      6            Meg Lanning    AUS  723 \n",
      "                                      7            Amy Satterthwaite    NZ  715 \n",
      "                                      8            Natalie Sciver    ENG  706 \n",
      "                                      9            Smriti Mandhana    IND  701 \n",
      "                                      10            Laura Wolvaardt    SA  683 \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import regex as re\n",
    "odi_page1=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\") \n",
    "odi_soup1=BeautifulSoup(odi_page1.content)\n",
    "top_batsman=odi_soup1.find_all('tr',class_=\"table-body\")\n",
    "first=odi_soup1.find_all('a',class_=\"rankings-block__banner-link\")\n",
    "batsman=[]\n",
    "first_rank=[]\n",
    "for i in first:\n",
    "    for  j in i.find_all(\"div\",class_=\"rankings-block__top-player\"):\n",
    "        for  k in j.find_all(\"div\",class_=\"rankings-block__banner--name\"):\n",
    "            first_rank.append(i.text.replace(\"\\n\",\" \"))\n",
    "for i in top_batsman:\n",
    "    for  j in i.find_all(\"td\",class_=\"table-body__cell name\"):\n",
    "        for  k in j.find_all(\"a\"):\n",
    "            batsman.append(i.text.replace(\"\\n\",\" \"))\n",
    "print(\"          \",first_rank[0])\n",
    "for r in range(0,9):\n",
    "      print(batsman[r])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ab18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import regex as re\n",
    "odi_page1=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\") \n",
    "odi_soup1=BeautifulSoup(odi_page1.content)\n",
    "top_bowler=odi_soup1.find_all(\"div\",class_=\"rankings-block__container\")\n",
    "first=odi_soup1.find_all('a',class_=\"rankings-block__banner-link\")\n",
    "bowler=[]\n",
    "info=[]\n",
    "for i in top_bowler:\n",
    "    for  j in i.find_all(\"tr\",class_=\"table-body\"):\n",
    "        for  k in j.find_all(\"td\",class_=\"table-body__cell name\"):\n",
    "            for  l in k.find_all(\"a\",href=\"/rankings/womens/player-rankings/997\"):\n",
    "                bowler.append(i.text.strip())\n",
    "print(bowler[0].replace(\"\\n\",\"\\t\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a25937",
   "metadata": {},
   "source": [
    "Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "311edfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 . Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)   2.3GHz Mediatek Helio G35 Octa core Processor  \n",
      "1 . Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)   2GHz Octa-core Helio G25 Processor   5000 mAh Battery  \n",
      "2 . Oppo A31 (Fantasy White, 6GB RAM, 128GB Storage) with No Cost EMI/Additional Exchange Offers  \n",
      "3 . Tecno Spark 7T(Jewel Blue, 4GB RAM, 64GB Storage) 6000 mAh Battery  48 MP AI Dual Rear Camera  \n",
      "4 . Samsung Galaxy M11 (Black, 4GB RAM, 64GB Storage) with No Cost EMI/Additional Exchange Offers  \n",
      "5 . Samsung Galaxy M31 (Ocean Blue, 8GB RAM, 128GB Storage) 6 Months Free Screen Replacement for Prime  \n",
      "6 . Oppo A31 (Mystery Black, 6GB RAM, 128GB Storage) with No Cost EMI/Additional Exchange Offers  \n",
      "7 . Redmi 9 (Carbon Black, 4GB RAM, 64GB Storage)   2.3GHz Mediatek Helio G35 Octa core Processor  \n",
      "8 . Redmi 9A(Midnight Black 3GB RAM 32GB Storage)   2GHz Octa-core Helio G25 Processor   5000 mAh Battery  \n",
      "9 . realme C11 (2021) (Cool Blue, 2GB RAM, 32GB Storage) with No Cost EMI/Additional Exchange Offers  \n",
      "10 . Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storage) - 48MP Quad Camera & Full HD+ Display  \n",
      "11 . Redmi 9A (Sea Blue 3GB RAM 32GB Storage)  2GHz Octa-core Helio G25 Processor   5000 mAh Battery  \n",
      "12 . Samsung Galaxy M12 (Black,4GB RAM, 64GB Storage) 6000 mAh with 8nm Processor   True 48 MP Quad Camera   90Hz Refresh Rate  \n",
      "13 . Redmi 9 (Sporty Orange, 4GB RAM, 64GB Storage)   2.3GHz Mediatek Helio G35 Octa core Processor  \n",
      "14 . Redmi 9A (Midnight Black 2GB RAM 32GB Storage)   2GHz Octa-core Helio G25 Processor   5000 mAh Battery  \n",
      "15 . Redmi 9A (Sea Blue 2GB RAM 32GB Storage)   2GHz Octa-core Helio G25 Processor   5000 mAh Battery  \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "amazon_page1=requests.get(\"https://www.amazon.in/Mobile-Phone-Under-20000/s?k=Mobile+Phone+Under+20000\")\n",
    "amazon_soup1=BeautifulSoup(amazon_page1.content)\n",
    "amazon=amazon_soup1.find_all(\"h2\")\n",
    "mobile=[]\n",
    "for i in amazon:\n",
    "    for  j in i.find_all(\"a\"): \n",
    "        mobile.append(i.text.replace(\"|\",' '))       \n",
    "for r in range(0,len(mobile)):\n",
    "    print(r,\".\",mobile[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0addd4e0",
   "metadata": {},
   "source": [
    "8.Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fc68bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today -----> Mostly cloudy, then gradually becoming sunny, with a high near 70. West southwest wind 5 to 14 mph, with gusts as high as 20 mph.  \n",
      "\n",
      "Tonight -----> Increasing clouds, with a low around 56. West southwest wind 6 to 13 mph, with gusts as high as 22 mph.  \n",
      "\n",
      "Friday -----> Mostly cloudy, then gradually becoming sunny, with a high near 69. West southwest wind 6 to 14 mph, with gusts as high as 21 mph.  \n",
      "\n",
      "Friday Night -----> Increasing clouds, with a low around 56. Southwest wind 7 to 14 mph, with gusts as high as 23 mph.  \n",
      "\n",
      "Saturday -----> Partly sunny, with a high near 67. Southwest wind 7 to 14 mph, with gusts as high as 18 mph.  \n",
      "\n",
      "Saturday Night -----> Mostly cloudy, with a low around 56. \n",
      "\n",
      "Sunday -----> Mostly sunny, with a high near 69. \n",
      "\n",
      "Sunday Night -----> Partly cloudy, with a low around 56. \n",
      "\n",
      "Monday -----> Mostly sunny, with a high near 68. \n",
      "\n",
      "Monday Night -----> Partly cloudy, with a low around 55. \n",
      "\n",
      "Tuesday -----> Mostly sunny, with a high near 66. \n",
      "\n",
      "Tuesday Night -----> Partly cloudy, with a low around 55. \n",
      "\n",
      "Wednesday -----> Mostly sunny, with a high near 66. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "weather_page1=requests.get(\"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YQA-3ugzbIU\")\n",
    "weather_soup1=BeautifulSoup(weather_page1.content)\n",
    "weather=weather_soup1.find_all(\"div\",class_=\"col-sm-10 forecast-text\")\n",
    "day=weather_soup1.find_all(\"div\",class_=\"col-sm-2 forecast-label\")\n",
    "days=[]\n",
    "report=[]\n",
    "for i in weather: \n",
    "        report.append(i.text.replace(\"\\n\",' ')) \n",
    "for j in day:\n",
    "    for  k in j.find_all(\"b\"): \n",
    "        days.append(j.text.replace(\"\\n\",' ')) \n",
    "for r in range(0,len(report)):          \n",
    "    print(days[r],\"----->\",report[r],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914d0ec5",
   "metadata": {},
   "source": [
    "9.Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company name, CTC, and apply date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd609634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decathlon Sport India Private Limited \n",
      " Start date                            Starts Immediately                        CTC  3.3 - 4.5 LPA\n",
      "Build With Innovation Private Limited \n",
      " Start date                            Starts Immediately                        CTC  3.3 - 4.5 LPA\n",
      "Inferigence Quotient LLP \n",
      " Apply By21 Aug' 21\n",
      "Internshala \n",
      " Start date                            Starts Immediately                        CTC  4 - 6 LPA\n",
      "Unicornready \n",
      " Start date                            Starts Immediately                        CTC  4 - 6 LPA\n",
      "Velocity Media Networks \n",
      " Apply By28 Aug' 21\n",
      "New Way Professionals Private Limited \n",
      " Start date                            Starts Immediately                        CTC  3 - 3.6 LPA\n",
      "Rang De \n",
      " Start date                            Starts Immediately                        CTC  3 - 3.6 LPA\n",
      "SafeSquid Labs \n",
      " Apply By28 Aug' 21\n",
      "Signals & Systems India Private Limited \n",
      " Start date                            Starts Immediately                        CTC  5 - 6.8 LPA\n",
      "Wisestep \n",
      " Start date                            Starts Immediately                        CTC  5 - 6.8 LPA\n",
      "Nucros Science & Taste \n",
      " Apply By28 Aug' 21\n",
      "Nikulsan Technologies Private Limited \n",
      " Start date                            Starts Immediately                        CTC  3 LPA\n",
      "Habitate Technologies Private Limited \n",
      " Start date                            Starts Immediately                        CTC  3 LPA\n",
      "School Of Excellence \n",
      " Apply By28 Aug' 21\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "job_page1=requests.get(\"https://internshala.com/fresher-jobs/\")\n",
    "job_soup1=BeautifulSoup(job_page1.content)\n",
    "fresher=job_soup1.find_all(\"div\",class_=\"heading_6 company_name\")\n",
    "detail=job_soup1.find_all(\"div\",class_=\"other_detail_item_row\")\n",
    "company=[]\n",
    "info=[]\n",
    "for i in fresher:\n",
    "    for j in i.find_all(\"a\"):                   \n",
    "        company.append(i.text.strip()) \n",
    "for i in detail:\n",
    "    for j in i.find_all(\"div\",class_=\"other_detail_item\"):                   \n",
    "        info.append(i.text.strip()) \n",
    "               \n",
    "for r in range(0,15):          \n",
    "    print(company[r].strip(),\"\\n\",info[r].replace(\"\\n\",\"\"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d265aeb8",
   "metadata": {},
   "source": [
    "10. Write a python program to scrape house details from https://www.nobroker.in/ for any location. It should include house title, location, area, emi and price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b52aa74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 BHK Flat  For Sale  In Anirudh Prashanth Castle In Pallikaranai  \n",
      " Under Loan₹ 1,169 sqftBuiltup₹42,985/MonthEstimated EMI₹75 Lacs₹6,416 per sq.ft. \n",
      "\n",
      "3 BHK In Independent House  For Sale  In Pallikaranai  \n",
      " Not under loan₹ 1,673 sqftBuiltup₹51,583/MonthEstimated EMI₹90 Lacs₹5,380 per sq.ft. \n",
      "\n",
      "3 BHK Apartment  For Sale  In Newry Sobhita In Pallikaranai  \n",
      " Not under loan₹ 1,447 sqftBuiltup₹48,717/MonthEstimated EMI₹85 Lacs₹5,874 per sq.ft. \n",
      "\n",
      "3 BHK Apartment  For Sale  In Krishna Accolade In Medavakkam  \n",
      " Not under loan₹ 1,535 sqftBuiltup₹63,045/MonthEstimated EMI₹1.1 Crores₹7,166 per sq.ft. \n",
      "\n",
      "3 BHK In Independent House  For Sale  In 16th Street, Pallikaranai  \n",
      " Not under loan₹ 1,100 sqftBuiltup₹42,985/MonthEstimated EMI₹75 Lacs₹6,818 per sq.ft. \n",
      "\n",
      "3 BHK Flat  For Sale  In Priya Platinum  In Annamalai Street, Pallikaranai  \n",
      " Not under loan₹ 1,122 sqftBuiltup₹40,120/MonthEstimated EMI₹70 Lacs₹6,239 per sq.ft. \n",
      "\n",
      "3 BHK In Independent House  For Sale  In Labour Colony, Pallikaranai  \n",
      " Not under loan₹ 2,000 sqftBuiltup₹74,508/MonthEstimated EMI₹1.3 Crores₹6,500 per sq.ft. \n",
      "\n",
      "3 BHK Apartment  For Sale  In Green Court In Medavakkam  \n",
      " Not under loan₹ 1,157 sqftBuiltup₹32,955/MonthEstimated EMI₹57.5 Lacs₹4,970 per sq.ft. \n",
      "\n",
      "3 BHK In Independent House  For Sale  In Medavakkam  \n",
      " Under Loan₹ 1,400 sqftBuiltup₹57,314/MonthEstimated EMI₹1 Crore₹7,143 per sq.ft. \n",
      "\n",
      "3 BHK Flat  For Sale  In Guru Krupa Apartment  In Pallikaranai  \n",
      " Not under loan₹ 1,220 sqftBuiltup₹40,120/MonthEstimated EMI₹70 Lacs₹5,738 per sq.ft. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "house_page1=requests.get(\"https://www.nobroker.in/property/sale/chennai/Chennai%20South?type=BHK3&searchParam=W3sibGF0IjoxMi45MjA0NDkxLCJsb24iOjgwLjIwOTgyMTksInBsYWNlSWQiOiJDaElKZVl6bGVaaGRVam9SM21pTk1GaTBNalkiLCJwbGFjZU5hbWUiOiJDaGVubmFpIFNvdXRoIn1d&radius=2.0\")\n",
    "house_soup1=BeautifulSoup(house_page1.content)\n",
    "house=house_soup1.find_all(\"div\",class_=\"nb__17R6o\")\n",
    "name=house_soup1.find_all(\"h2\",class_=\"heading-6 font-semi-bold nb__1AShY\")\n",
    "info=[]\n",
    "owner=[]\n",
    "info1=[]\n",
    "for i in house:\n",
    "    info.append(i.text.replace(\"\\n\",\" \"))\n",
    "for j in name:\n",
    "    owner.append(j.text.replace(\"\\n\",\"\"))\n",
    "for r in range(0,len(owner)):\n",
    "    print(owner[r],\"\\n\",info[r],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b136bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
