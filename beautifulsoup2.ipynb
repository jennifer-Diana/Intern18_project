{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a2e29a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\my pc\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: req in c:\\users\\my pc\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\my pc\\anaconda3\\lib\\site-packages (from req) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install req\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde1f2f",
   "metadata": {},
   "source": [
    "6.Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape: i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating. \n",
    "一\tii) Top 10 women’s ODI players along with the records of their team and rating. \n",
    "一\tiii) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54655926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 1   Australia AUS  18 2,955                              164                                ']\n",
      " 2   England ENG  20 2,370 119 \n",
      " 3   South Africa SA  24 2,828 118 \n",
      " 4   India IND  23 2,535 110 \n",
      " 5   New Zealand NZ  21 1,947 93 \n",
      " 6   West Indies WI  17 1,427 84 \n",
      " 7   Pakistan PAK  20 1,496 75 \n",
      " 8   Bangladesh BAN  5 306 61 \n",
      " 9   Sri Lanka SL  11 519 47 \n",
      " 10   Ireland IRE  2 25 13 \n"
     ]
    }
   ],
   "source": [
    "odi_page=requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\") \n",
    "odi_soup=BeautifulSoup(odi_page.content)\n",
    "top_team=odi_soup.find_all('tr',class_=\"table-body\")\n",
    "info_team=odi_soup.find_all('tr',class_=\"rankings-block__banner\")\n",
    "team=[]\n",
    "info=[]\n",
    "for i in info_team:\n",
    "    for m in i.find_all(\"td\",class_=\"rankings-block__banner--team-name\"):\n",
    "        for l in m.find_all(\"span\",class_=\"u-hide-phablet\"):\n",
    "            info.append(i.text.replace(\"\\n\",\" \"))\n",
    "for i in top_team:\n",
    "    for j in i.find_all(\"td\",class_=\"table-body__cell rankings-table__team\"):\n",
    "        for k in j.find_all(\"span\",class_=\"u-hide-phablet\"):\n",
    "            team.append(i.text.replace(\"\\n\",\" \"))\n",
    "\n",
    "print(info)\n",
    "for r in range(0,len(team)):\n",
    "    print(team[r])\n",
    "##print(top_team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "926a3b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      1            Mithali Raj   IND                             762       \n",
      "                                      2            Lizelle Lee    SA  758 \n",
      "                                      3            Alyssa Healy    AUS  756 \n",
      "                                      4            Tammy Beaumont    ENG  754 \n",
      "                                      5            Stafanie Taylor    WI  736 \n",
      "                                      6            Meg Lanning    AUS  723 \n",
      "                                      7            Amy Satterthwaite    NZ  715 \n",
      "                                      8            Natalie Sciver    ENG  706 \n",
      "                                      9            Smriti Mandhana    IND  701 \n",
      "                                      10            Laura Wolvaardt    SA  683 \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "imp Regul\n",
    "odi_page1=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\") \n",
    "odi_soup1=BeautifulSoup(odi_page1.content)\n",
    "top_batsman=odi_soup1.find_all('tr',class_=\"table-body\")\n",
    "first=odi_soup1.find_all('a',class_=\"rankings-block__banner-link\")\n",
    "batsman=[]\n",
    "first_rank=[]\n",
    "for i in first:\n",
    "    for  j in i.find_all(\"div\",class_=\"rankings-block__top-player\"):\n",
    "        for  k in j.find_all(\"div\",class_=\"rankings-block__banner--name\"):\n",
    "            first_rank.append(i.text.replace(\"\\n\",\" \"))\n",
    "for i in top_batsman:\n",
    "    for  j in i.find_all(\"td\",class_=\"table-body__cell name\"):\n",
    "        for  k in j.find_all(\"a\"):\n",
    "            batsman.append(i.text.replace(\"\\n\",\" \"))\n",
    "print(\"          \",first_rank[0])\n",
    "for r in range(0,9):\n",
    "      print(batsman[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74157b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import regex as re\n",
    "odi_page1=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\") \n",
    "odi_soup1=BeautifulSoup(odi_page1.content)\n",
    "top_bowler=odi_soup1.find_all(\"div\",class_=\"rankings-block__container\")\n",
    "first=odi_soup1.find_all('a',class_=\"rankings-block__banner-link\")\n",
    "bowler=[]\n",
    "info=[]\n",
    "for i in top_bowler:\n",
    "    for  j in i.find_all(\"tr\",class_=\"table-body\"):\n",
    "        for  k in j.find_all(\"td\",class_=\"table-body__cell name\"):\n",
    "            for  l in k.find_all(\"a\",href=\"/rankings/womens/player-rankings/997\"):\n",
    "                bowler.append(i.text.strip())\n",
    "print(bowler[0].replace(\"\\n\",\"\\t\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fcb2e4",
   "metadata": {},
   "source": [
    "Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33b313b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 . Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)   Extra INR 200 Amazon Pay Cashback   2.3GHz Mediatek Helio G35 Octa core Processor  \n",
      "1 . Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)   2GHz Octa-core Helio G25 Processor   5000 mAh Battery  \n",
      "2 . Tecno Spark 7T(Jewel Blue, 4GB RAM, 64GB Storage) 6000 mAh Battery  48 MP AI Dual Rear Camera, 6.52 Handy Size  \n",
      "3 . Oppo A31 (Fantasy White, 6GB RAM, 128GB Storage) with No Cost EMI/Additional Exchange Offers  \n",
      "4 . Samsung Galaxy M31 (Ocean Blue, 8GB RAM, 128GB Storage) 6 Months Free Screen Replacement for Prime  \n",
      "5 . Samsung Galaxy M11 (Black, 4GB RAM, 64GB Storage) with No Cost EMI/Additional Exchange Offers  \n",
      "6 . realme C11 (2021) (Cool Blue, 2GB RAM, 32GB Storage) with No Cost EMI/Additional Exchange Offers  \n",
      "7 . Oppo A31 (Mystery Black, 6GB RAM, 128GB Storage) with No Cost EMI/Additional Exchange Offers  \n",
      "8 . Samsung Galaxy M51 (Electric Blue, 6GB RAM, 128GB Storage) 6 Months Free Screen Replacement for Prime  \n",
      "9 . Redmi 9 (Sporty Orange, 4GB RAM, 64GB Storage)   Extra INR 200 Amazon Pay Cashback   2.3GHz Mediatek Helio G35 Octa core Processor  \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "amazon_page1=requests.get(\"https://www.amazon.in/Mobile-Phone-Under-20000/s?k=Mobile+Phone+Under+20000\")\n",
    "amazon_soup1=BeautifulSoup(amazon_page1.content)\n",
    "amazon=amazon_soup1.find_all(\"h2\")\n",
    "mobile=[]\n",
    "for i in amazon:\n",
    "    for  j in i.find_all(\"a\"): \n",
    "        mobile.append(i.text.replace(\"|\",' '))       \n",
    "for r in range(0,10):          \n",
    "    print(r,\".\",mobile[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36878d1",
   "metadata": {},
   "source": [
    "8.Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04f42d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today -----> A 20 percent chance of showers before 11am.  Sunny, with a high near 73. Breezy, with a west southwest wind 10 to 15 mph increasing to 17 to 22 mph in the afternoon. Winds could gust as high as 29 mph.  \n",
      "\n",
      "Tonight -----> Partly cloudy, with a low around 57. Breezy, with a west wind 18 to 23 mph decreasing to 10 to 15 mph in the evening. Winds could gust as high as 29 mph.  \n",
      "\n",
      "Wednesday -----> Mostly sunny, with a high near 71. Breezy, with a west wind 14 to 19 mph increasing to 20 to 25 mph in the afternoon. Winds could gust as high as 32 mph.  \n",
      "\n",
      "Wednesday Night -----> Mostly cloudy, with a low around 57. Breezy, with a west southwest wind 20 to 25 mph decreasing to 13 to 18 mph after midnight. Winds could gust as high as 33 mph.  \n",
      "\n",
      "Thursday -----> Mostly sunny, with a high near 70. Breezy, with a west southwest wind 10 to 15 mph increasing to 18 to 23 mph in the afternoon. Winds could gust as high as 31 mph.  \n",
      "\n",
      "Thursday Night -----> Partly cloudy, with a low around 57. Breezy.  \n",
      "\n",
      "Friday -----> Mostly sunny, with a high near 70. \n",
      "\n",
      "Friday Night -----> Mostly cloudy, with a low around 56. \n",
      "\n",
      "Saturday -----> Mostly sunny, with a high near 68. \n",
      "\n",
      "Saturday Night -----> Mostly cloudy, with a low around 56. \n",
      "\n",
      "Sunday -----> Mostly sunny, with a high near 67. \n",
      "\n",
      "Sunday Night -----> Mostly cloudy, with a low around 56. \n",
      "\n",
      "Monday -----> Mostly sunny, with a high near 67. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "weather_page1=requests.get(\"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YQA-3ugzbIU\")\n",
    "weather_soup1=BeautifulSoup(weather_page1.content)\n",
    "weather=weather_soup1.find_all(\"div\",class_=\"col-sm-10 forecast-text\")\n",
    "day=weather_soup1.find_all(\"div\",class_=\"col-sm-2 forecast-label\")\n",
    "days=[]\n",
    "report=[]\n",
    "for i in weather: \n",
    "        report.append(i.text.replace(\"\\n\",' ')) \n",
    "for j in day:\n",
    "    for  k in j.find_all(\"b\"): \n",
    "        days.append(j.text.replace(\"\\n\",' ')) \n",
    "for r in range(0,len(report)):          \n",
    "    print(days[r],\"----->\",report[r],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854277fc",
   "metadata": {},
   "source": [
    "9.Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company name, CTC, and apply date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7473dd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decathlon Sport India Private Limited \n",
      " Start date                            Starts Immediately                        CTC  3.3 - 4.5 LPA\n",
      "Padhhigh \n",
      " Start date                            Starts Immediately                        CTC  3.3 - 4.5 LPA\n",
      "Snippt \n",
      " Apply By21 Aug' 21\n",
      "DataVinci Private Limited \n",
      " Start date                            Starts Immediately                        CTC  4 - 7 LPA\n",
      "Red Tree Design Studio Private Limited \n",
      " Start date                            Starts Immediately                        CTC  4 - 7 LPA\n",
      "HelloAR \n",
      " Apply By26 Aug' 21\n",
      "Best Roadways Limited \n",
      " Start date                            Starts Immediately                        CTC  4 - 5 LPA\n",
      "Advids \n",
      " Start date                            Starts Immediately                        CTC  4 - 5 LPA\n",
      "Habitate Technologies Private Limited \n",
      " Apply By26 Aug' 21\n",
      "Recruit CRM \n",
      " Start date                            Starts Immediately                        CTC  5 LPA\n",
      "Revo International LLP \n",
      " Start date                            Starts Immediately                        CTC  5 LPA\n",
      "Startxlabs Technologies Private Limited \n",
      " Apply By26 Aug' 21\n",
      "Startxlabs Technologies Private Limited \n",
      " Start date                            Starts Immediately                        CTC  3 LPA\n",
      "Softsensor.ai \n",
      " Start date                            Starts Immediately                        CTC  3 LPA\n",
      "Verzeo \n",
      " Apply By26 Aug' 21\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "job_page1=requests.get(\"https://internshala.com/fresher-jobs/\")\n",
    "job_soup1=BeautifulSoup(job_page1.content)\n",
    "fresher=job_soup1.find_all(\"div\",class_=\"heading_6 company_name\")\n",
    "detail=job_soup1.find_all(\"div\",class_=\"other_detail_item_row\")\n",
    "company=[]\n",
    "info=[]\n",
    "for i in fresher:\n",
    "    for j in i.find_all(\"a\"):                   \n",
    "        company.append(i.text.strip()) \n",
    "for i in detail:\n",
    "    for j in i.find_all(\"div\",class_=\"other_detail_item\"):                   \n",
    "        info.append(i.text.strip()) \n",
    "               \n",
    "for r in range(0,15):          \n",
    "    print(company[r].strip(),\"\\n\",info[r].replace(\"\\n\",\"\"))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18884936",
   "metadata": {},
   "source": [
    "10. Write a python program to scrape house details from https://www.nobroker.in/ for any location. It should include house title, location, area, emi and price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "49cac3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 BHK Flat  For Sale  In Anirudh Prashanth Castle In Pallikaranai  \n",
      " Under Loan₹ 1,169 sqftBuiltup₹42,985/MonthEstimated EMI₹75 Lacs₹6,416 per sq.ft. \n",
      "\n",
      "3 BHK In Independent House  For Sale  In Pallikaranai  \n",
      " Not under loan₹ 1,673 sqftBuiltup₹51,583/MonthEstimated EMI₹90 Lacs₹5,380 per sq.ft. \n",
      "\n",
      "3 BHK Apartment  For Sale  In Newry Sobhita In Pallikaranai  \n",
      " Not under loan₹ 1,447 sqftBuiltup₹48,717/MonthEstimated EMI₹85 Lacs₹5,874 per sq.ft. \n",
      "\n",
      "3 BHK Apartment  For Sale  In Krishna Accolade In Medavakkam  \n",
      " Not under loan₹ 1,535 sqftBuiltup₹63,045/MonthEstimated EMI₹1.1 Crores₹7,166 per sq.ft. \n",
      "\n",
      "3 BHK Flat  For Sale  In Mint Apartments, Pallikaranai In Mint Apartments  \n",
      " Not under loan₹ 1,141 sqftBuiltup₹31,379/MonthEstimated EMI₹54.75 Lacs₹4,798 per sq.ft. \n",
      "\n",
      "3 BHK In Independent House  For Sale  In 16th Street, Pallikaranai  \n",
      " Not under loan₹ 1,100 sqftBuiltup₹42,985/MonthEstimated EMI₹75 Lacs₹6,818 per sq.ft. \n",
      "\n",
      "3 BHK Flat  For Sale  In Priya Platinum  In Annamalai Street, Pallikaranai  \n",
      " Not under loan₹ 1,122 sqftBuiltup₹40,120/MonthEstimated EMI₹70 Lacs₹6,239 per sq.ft. \n",
      "\n",
      "3 BHK In Independent House  For Sale  In Labour Colony, Pallikaranai  \n",
      " Not under loan₹ 2,000 sqftBuiltup₹74,508/MonthEstimated EMI₹1.3 Crores₹6,500 per sq.ft. \n",
      "\n",
      "3 BHK Apartment  For Sale  In Green Court In Medavakkam  \n",
      " Not under loan₹ 1,157 sqftBuiltup₹32,955/MonthEstimated EMI₹57.5 Lacs₹4,970 per sq.ft. \n",
      "\n",
      "3 BHK In Independent House  For Sale  In Medavakkam  \n",
      " Under Loan₹ 1,400 sqftBuiltup₹57,314/MonthEstimated EMI₹1 Crore₹7,143 per sq.ft. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "house_page1=requests.get(\"https://www.nobroker.in/property/sale/chennai/Chennai%20South?type=BHK3&searchParam=W3sibGF0IjoxMi45MjA0NDkxLCJsb24iOjgwLjIwOTgyMTksInBsYWNlSWQiOiJDaElKZVl6bGVaaGRVam9SM21pTk1GaTBNalkiLCJwbGFjZU5hbWUiOiJDaGVubmFpIFNvdXRoIn1d&radius=2.0\")\n",
    "house_soup1=BeautifulSoup(house_page1.content)\n",
    "house=house_soup1.find_all(\"div\",class_=\"nb__17R6o\")\n",
    "name=house_soup1.find_all(\"h2\",class_=\"heading-6 font-semi-bold nb__1AShY\")\n",
    "info=[]\n",
    "owner=[]\n",
    "info1=[]\n",
    "for i in house:\n",
    "    info.append(i.text.replace(\"\\n\",\" \"))\n",
    "for j in name:\n",
    "    owner.append(j.text.replace(\"\\n\",\"\"))\n",
    "for r in range(0,len(owner)):\n",
    "    print(owner[r],\"\\n\",info[r],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a7e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1925738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
